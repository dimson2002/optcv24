# optcv24
# Задание 2.

Подготовка окружения и обучение простого классификатора на учебном датасете, например, cifar10.

Асеев Дмитрий, SGD, Adagrad.

Главными плюсами AdaGrad является адаптивная скорость обучения и преимущество на разреженных данных (если есть признаки, которые появляются нечасто, то оптимизатор будет давать этим признакам более высокий шаг, тем самым более значительно обновляя их).
А главным минусом является невозможность "перезагрузить" шаг в отличие от RMSProp или Adam. Adagrad не включает механизм, который бы "обнулял" или сглаживал накопленное значение градиента, из-за чего модель может существенно замедлится.

Я вдохновился идеей Валерия Рябинкина по запуску функции train два раза, поэтому я создал условие выбора оптимизатора:

    if optimizer_name == 'SGD':
        optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
    elif optimizer_name == 'Adam':
        optimizer = torch.optim.Adam(net.parameters(), lr=0.001)

Также в функцию добавляется логгирование потерь и считается средняя потеря за эпоху.

И дальше отрисовывается график.

И главное запустить функцию с два раза подряд:

    if __name__ == '__main__':
        sgd_losses = train(optimizer_n='SGD')
        adagrad_losses = train(optimizer_n='Adagrad')

        losses_dict = {'SGD': sgd_losses,
                   'Adagrad': adagrad_losses}
        plot_loss(losses_dict)

![loss_plot_comparison.png](loss_plot_comparison.png)


*ВЫВОД:* при данных условиях оптимизатор SGD показывает лучшую динамику обучения, более быстрое и более глубокое снижение функции потерь по сравнению с Adagrad.

**ПОЧЕМУ ТАК ВЫШЛО?**

Adagrad сильно адаптирует шаг обучения, и в данноом случае он, вероятно, слишком быстро становится маленьким. Это приводит к медленной сходимости по сравнению с более "агрессивным" и постоянным шагом у SGD.


# Задание 3

Оптимизация гиперпараметров с помощью optune.

Заменил линейную сеть на сверточную Conv2D - Flatten - {Linear - ReLU - Dropout} * n_layers

Также заменил датасет FashionMNIST на CIFAR10.

Надо было осуществить поиск по двум гиперпараметрам: ("n_layers", 1, 5) ; ("lr", 1e-5, 1e-1, log=True)

Вывод консоли:

    Study statistics: 
    Number of finished trials:  100
    Number of pruned trials:  78
    Number of complete trials:  22
    Best trial:
      Value:  0.5
    Params: 
        n_layers: 1
        n_units_l0: 302
        dropout_l0: 0.20513131103910964
        optimizer: RMSprop
        lr: 0.0006119827290096727

Вывод: оптимизация привела к тому, что большинство неэффективных конфигураций было отсеяно, и лучший вариант дает точность 50%. Это не очень высокий результат для CIFAR10, что указывает на необходимость либо расширения количества гиперпараметров, либо усложнения модели, либо увеличения эпох.

# Задание 4

Оптимизация модели с помощью библиотеки onnx.

Необходимо конвертировать модель в onnx и сравнить производительность (скорость и точность) с model.pth.


ONNX - открытая библиотека для представления моделей машинного и глубокого обучения. Она позволяет конвертировать модели, обученные в одном фреймворке глубокого обучения, в общий формат, который можно использовать в других фреймворках, что упрощает работу с моделями на разных платформах и инструментах.

ONNX использует оптимизации графа вычислений и также производит меньше накладных расходов на инференс.

Была добавлена функция benchmark_pytorch для создания вывода аналогичного ONNX.

Проверка проводилась на датасете CIFAR10, где тестовыми были - 10 тыс. фото.

Результаты работы обычной модели:

    --- Бенчмарк PyTorch модели ---
    Точность для класса plane: 44.5%
    Точность для класса car  : 65.6%
    Точность для класса bird : 11.6%
    Точность для класса cat  : 28.6%
    Точность для класса deer : 44.9%
    Точность для класса dog  : 38.5%
    Точность для класса frog : 61.5%
    Точность для класса horse: 55.7%
    Точность для класса ship : 77.4%
    Точность для класса truck: 40.8%
    Среднее время предсказания PyTorch, мкс: 1185.95
    Количество предсказаний 10000

Результаты работы ONNX модели:

    --- Бенчмарк ONNX модели ---
    Точность для класса plane: 44.5 %
    Точность для класса car  : 65.6 %
    Точность для класса bird : 11.6 %
    Точность для класса cat  : 28.6 %
    Точность для класса deer : 44.9 %
    Точность для класса dog  : 38.5 %
    Точность для класса frog : 61.5 %
    Точность для класса horse: 55.7 %
    Точность для класса ship : 77.4 %
    Точность для класса truck: 40.8 %
    Среднее время предсказания ONNX, мкс:  63.68110179901123
    Количество предсказаний:  10000

Модель ONNX предсказывает в 18 раз быстрее. При этом точность осталась на том же уровне. 
Можно сделать вывод, что конвертация прошла успешно. Такой прирост в скорости особенно заметен на CPU.